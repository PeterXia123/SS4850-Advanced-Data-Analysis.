\documentclass[11pt]{article}
\setlength{\topmargin}{-.5in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{-.25in}
\setlength{\textwidth}{6.5in}
\usepackage[all]{xy}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\hsp}{\hspace}
 \setlength{\baselineskip}{1.9em}
 \linespread{1.16}
 \usepackage{color,amssymb,epsfig,verbatim,amsmath}
\usepackage{listings}

\begin{document}

\hfill Instructor: L.-P. Chen

\begin{center}
\Large{\bf SS4850G Assignment \#2 
\\(Due April 3 2020)}
\end{center}

{\bf Please carefully read the following instructions:}

\begin{itemize}

\item {\bf There are 3 questions in this assignment. 4 marks for each subquestion.}

\item  {\bf Show all your works in details and provide your code for computations. Also, well summarize your numerical results in each question.}

\item {\bf This assignment is an INDIVIDUAL work. Plagiarism will earn ZERO mark.}

\item {\bf ONLY R functions/packages mentioned in this course are allowed.  Using other functions/packages that are not used in this course will lose marks.}


\item {\bf Submit your solutions to the Drop Box in the course site. Delayed submission will lose marks.}

%\item {\bf Please submit your hard copy in class.}
\end{itemize}

\clearpage

\begin{enumerate}

\item {\bf (Wine Data Set)} These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents (including  {\tt Alcohol}, {\tt Malic acid}, {\tt Ash}, {\tt Alcalinity of ash}, {\tt Magnesium}, {\tt Total phenols}, {\tt Flavanoids}, {\tt Nonflavanoid phenols}, {\tt Proanthocyanins}, {\tt Color intensity}, {\tt Hue,OD280/OD315 of diluted wines}, and {\tt Proline}) found in each of the three types of wines. The sample size is 178. The dataset is available in the course site. The main interest of this dataset is to study multiclassification of the three types of wines. Let $\widehat{y}$ denote the predicted class of observations.

\begin{itemize}

\item[(a)] Use nominal logistic regression in Section 2.3 to examine the multiclassification. The R function is {\bf multinom}. In addition, summarize the confusion table for $y$ and $\widehat{y}$, use macro averaged metrics to evaluate recall, precision, F-measure, and then conduct performance of classification.

\item[(b)] Use the methods in linear discriminant analysis and quadratic discriminant analysis to obtain $\widehat{y}$. In addition, summarize the confusion table for $y$ and $\widehat{y}$, use macro averaged metrics to evaluate recall, precision, F-measure, and then conduct performance of classification.

\item[(c)] Use the support vector machine method to obtain $\widehat{y}$. In addition, summarize the confusion table for $y$ and $\widehat{y}$, use macro averaged metrics to evaluate recall, precision, F-measure, and then conduct performance of classification.


\item[(d)] Summarize your findings  in (a)-(c).

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\item {\bf (Simulation studies)} Consider the following linear model:
\begin{eqnarray} \label{lm}
y = X_1 \beta_1 + X_2 \beta_2 + X_3 \beta_3 + X_4 \beta_4  - 4\sqrt{\rho} X_5 \beta_5 + \epsilon,
\end{eqnarray}
where $X = \left( X_1,\cdots,X_p \right)$ is a $p$-dimensional vector of covariates and each $X_k$ is generated from $N(0,1)$. The correlations of all $X_k$ except $X_5$ are $\rho$, while $X_5$ has the correlation $\sqrt{\rho}$ with all other $p-1$ variables. Suppose that the sample size is $n=200$.

\begin{itemize}

\item[(a)] Show that $X_5$ is marginally independent of $y$.


\item[(b)] Now, consider $p=1500$ and generate the artificial data based on model (\ref{lm}) for 1000 repetitions. Specifically, let $\beta_i=1$ for every $i=1,\cdots,5$ and set $\rho=0.7$. After that, use the SIS and iterated SIS methods to do variable selection and estimate the parameters associated with selected covariates. Finally, summarize the estimator in the following table:

\begin{table}[!ht]
       \huge
     \caption{Simulation result for (b)}

   \scriptsize

 \centering
  \renewcommand{\arraystretch}{0.9}
 \begin{tabular}{c c c c c}
 \\
 \hline
& $\|\Delta\beta\|_1$ & $\|\Delta\beta\|_2$ & \#S & \#FN \\
\hline
SIS & \\
Iterated SIS & \\ 
 \hline 
\end{tabular}

\end{table}


\item[(c)] Here we consider the scenario that is different from (b). Let $p=40$ and $X \sim N(0,\Sigma_X)$ with entry $(j,k)$ in $\Sigma_X$ being $0.5^{|j-k|}$ for $j,k=1,\cdots,p$. We generate the artificial data based on (\ref{lm}) for 1000 repetition with  $\beta_i=1$ for every $i=1,\cdots,5$. After that, use the lasso, adaptive lasso, and Elastic net (set $\alpha=0.5$) methods to estimate the parameters. Finally, summarize numerical results in the following table.


\begin{table}[!ht]
       \huge
     \caption{Simulation result for (c)}

   \scriptsize

 \centering
  \renewcommand{\arraystretch}{0.9}
 \begin{tabular}{c c c c c}
 \\
 \hline
& $\|\Delta\beta\|_1$ & $\|\Delta\beta\|_2$ & \#S & \#FN \\
\hline
lasso & \\
adaptive lasso & \\
Elastic net ($\alpha=0.5$) & \\ 
 \hline 
\end{tabular}

\end{table}



\item[(d)] Summarize your findings for parts (b) and (c), respectively.

\end{itemize}

{\bf Note:} Let $\widehat{\beta}$ be the estimator, then $\Delta\beta$ is defined as $\Delta\beta = \widehat{\beta} - \beta$ with the $i$th component being $\widehat{\beta}_i - \beta_i$. Therefore, $\|\Delta\beta\|_1$ and $\|\Delta\beta\|_2$ are defined as
\begin{itemize}
\item $\|\Delta\beta\|_1 = \sum \limits_{i=1}^p \left| \widehat{\beta}_i - \beta_i \right|$;
\item $\|\Delta\beta\|_2 = \sqrt{ \sum \limits_{i=1}^p \left( \widehat{\beta}_i - \beta_i \right)^2 }$.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\item In the class, we have discussed analysis of graphical models.

\begin{itemize}

\item[(a)] Show that a multivariate normal distribution with mean $\mu$ and covariance matrix $\Sigma$ can be expressed as the Gaussian graphical model.

\item[(b)] Comparisons with glasso and neighbourhood inference:

Consider the sample size $n=400$ and the dimensions of the Gaussian random vector $p=10$ and $50$. Please use the methods introduced in the class to generate {\it Lattice} and {\it Hub} graphical structures with 10 repetitions. Regarding the glasso method, choose $\rho=0.001, 0.01$, and 0.1. Then compute the {\it specificity} (Spe) and {\it Sensitivity} (Sen). Finally, summarize numerical results in the following table, and provide your comments on these two methods.

  \begin{table}[!ht]
       \huge
     \caption{Numerical results for the estimators of $\Theta$}

\normalsize

 \centering
 
 \begin{tabular}{c c c c  c cc}

 \\
 \hline\hline
$p$  & Model &  Method & $\rho$ &  & \multicolumn{2}{c} {  Estimator of $\Theta$ } \\ \cline{6-7}
 & & &  &   &  Spe & Sen

\\
 \hline 
% \hline 
10  & Lattice &   1 & 0.001 & &\\
         &            &      & 0.010 & & \\
         &        &    & 0.100 & &  \\
         &            &   2   & $\times$ & &  \\         
\cline{2-7}
 &Hub &   1 & 0.001 & &  \\
         &            &      & 0.010 & & \\
         &        &    & 0.100 & &  \\
         &            &   2   & $\times$ & & \\
 \hline 
% \hline 
50  & Lattice &   1 & 0.001 & &\\
         &            &      & 0.010 & & \\
         &        &    & 0.100 & &  \\
         &            &   2   & $\times$ & &  \\         
\cline{2-7}
 &Hub &   1 & 0.001 & &  \\
         &            &      & 0.010 & & \\
         &        &    & 0.100 & &  \\
         &            &   2   & $\times$ & & \\     
 \hline\hline
\end{tabular}
\\
\small
Method 1: glasso\ \ Method 2: neighbourhood inference. \ \ \ \ \  
\end{table} 

\end{itemize}

\end{enumerate}


\clearpage

{\bf Hint: Regarding simulation studies with 1000 repetitions.}


In Question 2, you are asked to use simulation studies with 1000 repetitions to estimate the parameters. Specifically, based on the $k$th artificial data that are independently generated, you are able to obtain the estimator, denoted by $\widehat{\beta}^{(k)}$. As a result, with 1000 repetitions, the final estimator is given by $\widehat{\beta} = \frac{1}{1000} \sum \limits_{k=1}^{1000} \widehat{\beta}^{(k)}$.

\end{document}
